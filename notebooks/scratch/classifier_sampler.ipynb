{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import ParameterSampler\n",
    "from scipy.stats import randint as sp_randint\n",
    "from scipy.stats import uniform\n",
    "import re\n",
    "\n",
    "# sklearn classifiers\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier, RidgeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need a class that creates all the parameters for the classifier and random search. Needs to be reproducible.\n",
    "\n",
    "Random search parameters:\n",
    "\n",
    "* random seed\n",
    "* number of iterations\n",
    "* under/over sampling method\n",
    "* imbalance ratio (for under/over sampling)\n",
    "* scaling method (e.g. standard scaling, or min/max, etc.)\n",
    "* features used\n",
    "    * how to repeatably select the appropriate features? Maybe randomly shuffle?\n",
    "    * use `random.choices` to select the features? Use `random.seed()` to set the seed.\n",
    "* number of features used\n",
    "* classifier used\n",
    "* data set used\n",
    "\n",
    "Dataset parameters (may be specific for dataset). Should probably store as a separate data card... For milling data set, parameters could be:\n",
    "\n",
    "* label meta-data (df_labels)\n",
    "* window size\n",
    "* stride\n",
    "* cut drop list\n",
    "\n",
    "Classifier parameters:\n",
    "* classifier\n",
    "* parameter sampler seed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# practice loading the datafram, selecting the column names, and randomly selecting n number of features (based on column names)\n",
    "\n",
    "def build_classifier_parameter_dict_named(clf, p_clf):\n",
    "\n",
    "    name = re.sub(\"'\", \"\", str(type(clf)).replace(\">\", \"\").split(\".\")[-1])\n",
    "\n",
    "    # rebuild the parameter dict and append the classifier name onto each parameter\n",
    "    classifier_parameters = {}\n",
    "    for k in p_clf:\n",
    "        classifier_parameters[str(name) + \"_\" + k] = p_clf[k]\n",
    "\n",
    "    return classifier_parameters\n",
    "\n",
    "\n",
    "def random_forest_classifier(sampler_seed, parameters_sample_dict=None):\n",
    "    if parameters_sample_dict is None:\n",
    "        parameters_sample_dict = {\n",
    "            \"n_estimators\": sp_randint(5, 500),\n",
    "            \"max_depth\": sp_randint(1, 500),\n",
    "            \"random_state\": sp_randint(1, 2 ** 16),\n",
    "            \"min_samples_leaf\": sp_randint(1, 10),\n",
    "            \"bootstrap\": [True, False],\n",
    "            \"class_weight\": ['balanced','balanced_subsample',None],\n",
    "        }\n",
    "\n",
    "    param_dict_raw = list(\n",
    "        ParameterSampler(\n",
    "            parameters_sample_dict, n_iter=1, random_state=sampler_seed\n",
    "        )\n",
    "    )[0]\n",
    "\n",
    "    clf = RandomForestClassifier(**p_clf)\n",
    "\n",
    "    return clf, param_dict_raw, build_classifier_parameter_dict_named(clf, p_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'RandomForestClassifier_bootstrap': False,\n",
       " 'RandomForestClassifier_class_weight': 'balanced',\n",
       " 'RandomForestClassifier_max_depth': 73,\n",
       " 'RandomForestClassifier_min_samples_leaf': 6,\n",
       " 'RandomForestClassifier_n_estimators': 340,\n",
       " 'RandomForestClassifier_random_state': 21441}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf, p_clf, param_dict_named = random_forest_classifier(1)\n",
    "param_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': False,\n",
       " 'class_weight': 'balanced',\n",
       " 'max_depth': 73,\n",
       " 'min_samples_leaf': 6,\n",
       " 'n_estimators': 340,\n",
       " 'random_state': 21441}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "daff1afd4d675d5e247c0a95a5de0c03bd87d8f7edee7cb37c539016070f1c16"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('featstore': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
